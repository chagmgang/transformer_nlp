{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python361064bitpytorchcondaed36d89d6ca44e38823f2dd584949822",
   "display_name": "Python 3.6.10 64-bit ('pytorch': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import json\n",
    "import torch\n",
    "import tokenization\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from transformer.model import GPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'kor_vocab_length': 50000,\n 'eng_vocab_length': 28998,\n 'd_model': 768,\n 'd_ff': 2048,\n 'd_k': 64,\n 'd_v': 64,\n 'num_layers': 12,\n 'num_heads': 8,\n 'start_word': '[SOS]',\n 'end_word': '[EOS]',\n 'sep_word': '[SEP]',\n 'cls_word': '[CLS]',\n 'pad_word': '[PAD]',\n 'mask_word': '[MASK]'}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read configuration file\n",
    "config = json.load(open('config.json'))\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configure device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['23',\n '##일',\n '업계에',\n '따',\n '##르',\n '##면',\n '이들',\n '3',\n '##사는',\n '최근',\n '열린',\n '각',\n '사',\n '주주',\n '##총회에서',\n '올해',\n '코',\n '##로',\n '##나',\n '##19',\n '여',\n '##파',\n '등으로',\n '반도체',\n '·',\n '디스플레이',\n '시장의',\n '대외',\n '불',\n '##확실',\n '##성',\n '##이',\n '높',\n '##아',\n '##질',\n '것으로',\n '전망',\n '##했다',\n '.']"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configure tokenizer\n",
    "tokenizer = tokenization.FullTokenizer(\n",
    "    vocab_file='vocab/kor_vocab.txt', do_lower_case=False)\n",
    "tokenizer.tokenize('23일 업계에 따르면 이들 3사는 최근 열린 각 사 주주총회에서 올해 코로나19 여파 등으로 반도체·디스플레이 시장의 대외 불확실성이 높아질 것으로 전망했다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[1, 47546, 198, 5489, 143, 3, 810, 3, 3873, 1533, 170, 7179, 36401, 47492, 47901, 416, 20249, 5101, 48189, 196, 7758, 135, 1918, 2082, 127, 14553, 10552, 47529, 275, 118, 40040, 222, 2082, 127, 14553, 47551, 609, 186, 40471, 40819, 2629, 147, 1418, 547, 104, 47567, 255, 162, 47709, 11060, 3089, 2769, 47440, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 27041, 143, 469, 1514, 4479, 162, 2397, 4734, 47505, 304, 1333, 5904, 47507, 139, 47468, 139, 10552, 18664, 1143, 47440, 47523, 27428, 47265, 1918, 28825, 3005, 47452, 36660, 2397, 4734, 18664, 119, 3542, 1270, 2858, 22812, 47483, 213, 5889, 47453, 4924, 3542, 5721, 47483, 213, 4972, 5509, 13938, 10233, 47488, 47522, 348, 47522, 241, 23017, 3, 47488, 47462, 47493, 34865, 6182, 36660, 47522, 5509, 469, 1514, 3542, 1367, 5181, 47551, 609, 186, 27041, 143, 155, 13701, 469, 1514, 3542, 6026, 37001, 148, 161, 47558, 47526, 47452, 292, 47483, 213, 14498, 115, 47440, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 47523, 6610, 21793, 47452, 27041, 32087, 2397, 4734, 469, 47530, 205, 6026, 31708, 3554, 118, 47517, 735, 286, 5489, 849, 837, 47452, 825, 47452, 4924, 1742, 1635, 35888, 47481, 124, 41921, 47483, 213, 118, 27360, 32191, 20312, 47440, 27080, 32191, 469, 40819, 35687, 5977, 36917, 23454, 2397, 40355, 18664, 18891, 155, 47440, 25660, 47453, 2397, 4734, 18664, 573, 4556, 47467, 1892, 9246, 37035, 33122, 32191, 162, 3, 47452, 47447, 47562, 17422, 47440, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n[[47546, 198, 5489, 143, 3, 810, 3, 3873, 1533, 170, 7179, 36401, 47492, 47901, 416, 20249, 5101, 48189, 196, 7758, 135, 1918, 2082, 127, 14553, 10552, 47529, 275, 118, 40040, 222, 2082, 127, 14553, 47551, 609, 186, 40471, 40819, 2629, 147, 1418, 547, 104, 47567, 255, 162, 47709, 11060, 3089, 2769, 47440, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [27041, 143, 469, 1514, 4479, 162, 2397, 4734, 47505, 304, 1333, 5904, 47507, 139, 47468, 139, 10552, 18664, 1143, 47440, 47523, 27428, 47265, 1918, 28825, 3005, 47452, 36660, 2397, 4734, 18664, 119, 3542, 1270, 2858, 22812, 47483, 213, 5889, 47453, 4924, 3542, 5721, 47483, 213, 4972, 5509, 13938, 10233, 47488, 47522, 348, 47522, 241, 23017, 3, 47488, 47462, 47493, 34865, 6182, 36660, 47522, 5509, 469, 1514, 3542, 1367, 5181, 47551, 609, 186, 27041, 143, 155, 13701, 469, 1514, 3542, 6026, 37001, 148, 161, 47558, 47526, 47452, 292, 47483, 213, 14498, 115, 47440, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [47523, 6610, 21793, 47452, 27041, 32087, 2397, 4734, 469, 47530, 205, 6026, 31708, 3554, 118, 47517, 735, 286, 5489, 849, 837, 47452, 825, 47452, 4924, 1742, 1635, 35888, 47481, 124, 41921, 47483, 213, 118, 27360, 32191, 20312, 47440, 27080, 32191, 469, 40819, 35687, 5977, 36917, 23454, 2397, 40355, 18664, 18891, 155, 47440, 25660, 47453, 2397, 4734, 18664, 573, 4556, 47467, 1892, 9246, 37035, 33122, 32191, 162, 3, 47452, 47447, 47562, 17422, 47440, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
    }
   ],
   "source": [
    "# define sample dataset\n",
    "dataset = [\n",
    "    '미성년자 열댓 명을 비롯해 여성 70여명을 대상으로 성 착취 동영상을 찍도록 하고 이를 텔레그램에서 유포한 이른바 텔레그램 n번방 사건에 대해 23일 정치권이 분노의 목소리를 내고 있다.',\n",
    "    '피의자에 대한 검찰의 포토라인 관행은 지난해 조국 정국에서 폐지됐다. 신 최고의원은 이를 지적하며 \"그때 포토라인 폐지가 수사기관 개혁이라고 주장했고, 인권 수사라고 주장했던 사람들은 이제 \\'그게 그거랑 같냐\\'를 들먹이며 그때 그 사람에 대한 수사와 지금 n번방 피의자나 박사에 대한 수사는 다르다고 할 것\"이라고 주장하기도 했다.',\n",
    "    '신 최고위원은 \"피의자를 포토라인에 세우는 것을 금지한 게 2019년 10월\"이라며 \"인권보호수사규칙을 제정하자고 주장한 장관이 누구인가. 검찰이 누구에 대해 수사를 하다가 압박으로 포토라인이 폐지되었나. 실제, 포토라인 폐지로 바로 수혜를 입은 사람이 누구의 가족이냐\"고 되물었다.']\n",
    "\n",
    "token_length = 128\n",
    "\n",
    "dec_inputs, dec_outputs = [], []\n",
    "for data in dataset:\n",
    "    token = [config['start_word']]\n",
    "    token.extend(tokenizer.tokenize(data)[:token_length])\n",
    "    token.append(config['end_word'])\n",
    "    dec_input = token[:-1]\n",
    "    dec_output = token[1:]\n",
    "    while len(dec_input) < token_length + 1:\n",
    "        dec_input.append(config['pad_word'])\n",
    "    while len(dec_output) < token_length + 1:\n",
    "        dec_output.append(config['pad_word'])\n",
    "\n",
    "    dec_input = tokenizer.convert_tokens_to_ids(dec_input)\n",
    "    dec_output = tokenizer.convert_tokens_to_ids(dec_output)\n",
    "\n",
    "    dec_inputs.append(dec_input)\n",
    "    dec_outputs.append(dec_output)\n",
    "\n",
    "print(dec_inputs)\n",
    "print(dec_outputs)\n",
    "\n",
    "dec_inputs = torch.as_tensor(dec_inputs, dtype=torch.long).to(device)\n",
    "dec_outputs = torch.as_tensor(dec_outputs, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "GPTModel(\n  (decoder): MaskedDecoder(\n    (tgt_emb): Embedding(50000, 768)\n    (pos_emb): PositionalEncoding(\n      (dropout): Dropout(p=0, inplace=False)\n    )\n    (layers): ModuleList(\n      (0): MaskedDecoderLayer(\n        (dec_self_attn): MultiHeadAttention(\n          (WQ): Linear(in_features=768, out_features=512, bias=True)\n          (WK): Linear(in_features=768, out_features=512, bias=True)\n          (WV): Linear(in_features=768, out_features=512, bias=True)\n          (linear): Linear(in_features=512, out_features=768, bias=True)\n          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n        (pos_ffn): PoswiseFeedForwardNet(\n          (l1): Linear(in_features=768, out_features=2048, bias=True)\n          (l2): Linear(in_features=2048, out_features=768, bias=True)\n          (relu): GELU()\n          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (1): MaskedDecoderLayer(\n        (dec_self_attn): MultiHeadAttention(\n          (WQ): Linear(in_features=768, out_features=512, bias=True)\n          (WK): Linear(in_features=768, out_features=512, bias=True)\n          (WV): Linear(in_features=768, out_features=512, bias=True)\n          (linear): Linear(in_features=512, out_features=768, bias=True)\n          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n        (pos_ffn): PoswiseFeedForwardNet(\n          (l1): Linear(in_features=768, out_features=2048, bias=True)\n          (l2): Linear(in_features=2048, out_features=768, bias=True)\n          (relu): GELU()\n          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (2): MaskedDecoderLayer(\n        (dec_self_attn): MultiHeadAttention(\n          (WQ): Linear(in_features=768, out_features=512, bias=True)\n          (WK): Linear(in_features=768, out_features=512, bias=True)\n          (WV): Linear(in_features=768, out_features=512, bias=True)\n          (linear): Linear(in_features=512, out_features=768, bias=True)\n          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n        (pos_ffn): PoswiseFeedForwardNet(\n          (l1): Linear(in_features=768, out_features=2048, bias=True)\n          (l2): Linear(in_features=2048, out_features=768, bias=True)\n          (relu): GELU()\n          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (3): MaskedDecoderLayer(\n        (dec_self_attn): MultiHeadAttention(\n          (WQ): Linear(in_features=768, out_features=512, bias=True)\n          (WK): Linear(in_features=768, out_features=512, bias=True)\n          (WV): Linear(in_features=768, out_features=512, bias=True)\n          (linear): Linear(in_features=512, out_features=768, bias=True)\n          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n        (pos_ffn): PoswiseFeedForwardNet(\n          (l1): Linear(in_features=768, out_features=2048, bias=True)\n          (l2): Linear(in_features=2048, out_features=768, bias=True)\n          (relu): GELU()\n          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (4): MaskedDecoderLayer(\n        (dec_self_attn): MultiHeadAttention(\n          (WQ): Linear(in_features=768, out_features=512, bias=True)\n          (WK): Linear(in_features=768, out_features=512, bias=True)\n          (WV): Linear(in_features=768, out_features=512, bias=True)\n          (linear): Linear(in_features=512, out_features=768, bias=True)\n          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n        (pos_ffn): PoswiseFeedForwardNet(\n          (l1): Linear(in_features=768, out_features=2048, bias=True)\n          (l2): Linear(in_features=2048, out_features=768, bias=True)\n          (relu): GELU()\n          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (5): MaskedDecoderLayer(\n        (dec_self_attn): MultiHeadAttention(\n          (WQ): Linear(in_features=768, out_features=512, bias=True)\n          (WK): Linear(in_features=768, out_features=512, bias=True)\n          (WV): Linear(in_features=768, out_features=512, bias=True)\n          (linear): Linear(in_features=512, out_features=768, bias=True)\n          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n        (pos_ffn): PoswiseFeedForwardNet(\n          (l1): Linear(in_features=768, out_features=2048, bias=True)\n          (l2): Linear(in_features=2048, out_features=768, bias=True)\n          (relu): GELU()\n          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (6): MaskedDecoderLayer(\n        (dec_self_attn): MultiHeadAttention(\n          (WQ): Linear(in_features=768, out_features=512, bias=True)\n          (WK): Linear(in_features=768, out_features=512, bias=True)\n          (WV): Linear(in_features=768, out_features=512, bias=True)\n          (linear): Linear(in_features=512, out_features=768, bias=True)\n          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n        (pos_ffn): PoswiseFeedForwardNet(\n          (l1): Linear(in_features=768, out_features=2048, bias=True)\n          (l2): Linear(in_features=2048, out_features=768, bias=True)\n          (relu): GELU()\n          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (7): MaskedDecoderLayer(\n        (dec_self_attn): MultiHeadAttention(\n          (WQ): Linear(in_features=768, out_features=512, bias=True)\n          (WK): Linear(in_features=768, out_features=512, bias=True)\n          (WV): Linear(in_features=768, out_features=512, bias=True)\n          (linear): Linear(in_features=512, out_features=768, bias=True)\n          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n        (pos_ffn): PoswiseFeedForwardNet(\n          (l1): Linear(in_features=768, out_features=2048, bias=True)\n          (l2): Linear(in_features=2048, out_features=768, bias=True)\n          (relu): GELU()\n          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (8): MaskedDecoderLayer(\n        (dec_self_attn): MultiHeadAttention(\n          (WQ): Linear(in_features=768, out_features=512, bias=True)\n          (WK): Linear(in_features=768, out_features=512, bias=True)\n          (WV): Linear(in_features=768, out_features=512, bias=True)\n          (linear): Linear(in_features=512, out_features=768, bias=True)\n          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n        (pos_ffn): PoswiseFeedForwardNet(\n          (l1): Linear(in_features=768, out_features=2048, bias=True)\n          (l2): Linear(in_features=2048, out_features=768, bias=True)\n          (relu): GELU()\n          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (9): MaskedDecoderLayer(\n        (dec_self_attn): MultiHeadAttention(\n          (WQ): Linear(in_features=768, out_features=512, bias=True)\n          (WK): Linear(in_features=768, out_features=512, bias=True)\n          (WV): Linear(in_features=768, out_features=512, bias=True)\n          (linear): Linear(in_features=512, out_features=768, bias=True)\n          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n        (pos_ffn): PoswiseFeedForwardNet(\n          (l1): Linear(in_features=768, out_features=2048, bias=True)\n          (l2): Linear(in_features=2048, out_features=768, bias=True)\n          (relu): GELU()\n          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (10): MaskedDecoderLayer(\n        (dec_self_attn): MultiHeadAttention(\n          (WQ): Linear(in_features=768, out_features=512, bias=True)\n          (WK): Linear(in_features=768, out_features=512, bias=True)\n          (WV): Linear(in_features=768, out_features=512, bias=True)\n          (linear): Linear(in_features=512, out_features=768, bias=True)\n          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n        (pos_ffn): PoswiseFeedForwardNet(\n          (l1): Linear(in_features=768, out_features=2048, bias=True)\n          (l2): Linear(in_features=2048, out_features=768, bias=True)\n          (relu): GELU()\n          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (11): MaskedDecoderLayer(\n        (dec_self_attn): MultiHeadAttention(\n          (WQ): Linear(in_features=768, out_features=512, bias=True)\n          (WK): Linear(in_features=768, out_features=512, bias=True)\n          (WV): Linear(in_features=768, out_features=512, bias=True)\n          (linear): Linear(in_features=512, out_features=768, bias=True)\n          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n        (pos_ffn): PoswiseFeedForwardNet(\n          (l1): Linear(in_features=768, out_features=2048, bias=True)\n          (l2): Linear(in_features=2048, out_features=768, bias=True)\n          (relu): GELU()\n          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (projection): Linear(in_features=768, out_features=50000, bias=False)\n)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## configure model, optimizer, criterion\n",
    "pad_index = tokenizer.convert_tokens_to_ids([config['pad_word']])[0]\n",
    "\n",
    "generator = GPTModel(\n",
    "    vocab_size=config['kor_vocab_length'],\n",
    "    d_model=config['d_model'],\n",
    "    d_ff=config['d_ff'],\n",
    "    d_k=config['d_k'], d_v=config['d_v'],\n",
    "    n_heads=config['num_heads'], n_layers=config['num_layers'],\n",
    "    pad_index=pad_index, device=device).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(generator.parameters(), lr=5e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0 10.976317405700684\n1 7.627902507781982\n2 6.312865257263184\n3 6.122442722320557\n4 5.987438201904297\n5 5.792433261871338\n6 5.655355930328369\n7 5.556546211242676\n8 5.4174957275390625\n9 5.251761436462402\n10 5.097161293029785\n11 4.957839488983154\n12 4.8264031410217285\n13 4.694883346557617\n14 4.557570457458496\n15 4.413417339324951\n16 4.265126705169678\n17 4.115043640136719\n18 3.963460922241211\n19 3.8107032775878906\n20 3.6577868461608887\n21 3.5047521591186523\n22 3.350825071334839\n23 3.1961829662323\n24 3.042105197906494\n25 2.8892598152160645\n26 2.7372820377349854\n27 2.586233615875244\n28 2.4370338916778564\n29 2.2905523777008057\n30 2.1473488807678223\n31 2.0077075958251953\n32 1.871577262878418\n33 1.7393180131912231\n34 1.6119086742401123\n35 1.4898340702056885\n36 1.373130202293396\n37 1.2622491121292114\n38 1.1575462818145752\n39 1.0590561628341675\n40 0.9672638773918152\n41 0.8827014565467834\n42 0.8052138686180115\n43 0.734371542930603\n44 0.6698440313339233\n45 0.6113075613975525\n46 0.5584662556648254\n47 0.5109895467758179\n48 0.46836021542549133\n49 0.4300125539302826\n50 0.39552536606788635\n51 0.36455318331718445\n52 0.33671578764915466\n53 0.31164151430130005\n54 0.2890236973762512\n55 0.2685995101928711\n56 0.25011691451072693\n57 0.23334816098213196\n58 0.2181050032377243\n59 0.20422981679439545\n60 0.19158302247524261\n61 0.18003980815410614\n62 0.16949017345905304\n63 0.15983562171459198\n64 0.15098518133163452\n65 0.14285972714424133\n66 0.13539353013038635\n67 0.12853120267391205\n68 0.12222260236740112\n69 0.11641816049814224\n70 0.1110711321234703\n71 0.10613997280597687\n72 0.10158855468034744\n73 0.09738458693027496\n74 0.09349782764911652\n75 0.08990012109279633\n76 0.08656571060419083\n77 0.08347181230783463\n78 0.0805973932147026\n79 0.07792304456233978\n80 0.07543081790208817\n81 0.07310495525598526\n82 0.07093097269535065\n83 0.06889620423316956\n84 0.06698933243751526\n85 0.06520047038793564\n86 0.06351969391107559\n87 0.06193825975060463\n88 0.060447998344898224\n89 0.05904200300574303\n90 0.057713668793439865\n91 0.05645706504583359\n92 0.05526651069521904\n93 0.05413725599646568\n94 0.05306466668844223\n95 0.05204487964510918\n96 0.05107368528842926\n97 0.05014791712164879\n98 0.049264825880527496\n99 0.048421524465084076\n"
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    dec_logits, attns = generator(dec_inputs)\n",
    "    loss = criterion(\n",
    "        dec_logits.view(-1, dec_logits.size(-1)),\n",
    "        dec_outputs.contiguous().view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(epoch, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "----------------------\ninput text : ['[SOS]', '신', '최고', '##위원은', '\"', '피의', '##자를', '포토', '##라인', '##에', '세', '##우', '##는', '것을', '금지', '##한', '게', '201', '##9', '##년']\npredict_text : [SOS] 신 최고위원은 \" 피의자를 포토라인에 세우는 것을 금지한 게 2019년 10월 \" 이라며 \" 인권보호수사규칙을 제정하자고 주장한 장관이 누구인가 . 검찰이 누구에 대해 수사를 하다가 압박으로 포토라인이 폐지되었나 . 실제 , 포토라인 폐지로 바로 수혜를 입은 사람이 누구의 [UNK] \" 고 되물었다 . [EOS]\n"
    }
   ],
   "source": [
    "generator.eval()\n",
    "\n",
    "eos_flag = tokenizer.convert_tokens_to_ids([config['end_word']])[0]\n",
    "test_sentence = '신 최고위원은 \"피의자를 포토라인에 세우는 것을 금지한 게 2019년'\n",
    "\n",
    "tokens = [config['start_word']]\n",
    "tokens.extend(tokenizer.tokenize(test_sentence))\n",
    "test_sentence_dec = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "while test_sentence_dec[-1] != eos_flag or len(test_sentence_dec) > 100:\n",
    "    dec_inputs = torch.as_tensor([test_sentence_dec], dtype=torch.long).to(device)\n",
    "    dec_logits, _ = generator(dec_inputs)\n",
    "    predict = torch.argmax(dec_logits, axis=2)[:, -1].squeeze().detach().cpu().numpy()\n",
    "    test_sentence_dec.append(int(predict))\n",
    "    \n",
    "print('----------------------')\n",
    "print(f'input text : {tokens}')\n",
    "predict_text = ' '.join(tokenizer.convert_ids_to_tokens(test_sentence_dec))\n",
    "predict_text = predict_text.replace(\" ##\", \"\")\n",
    "predict_text = predict_text.replace(\"##\", \"\")\n",
    "print(f'predict_text : {predict_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}