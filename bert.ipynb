{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python361064bitpytorchcondaed36d89d6ca44e38823f2dd584949822",
   "display_name": "Python 3.6.10 64-bit ('pytorch': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import json\n",
    "import torch\n",
    "import datasets\n",
    "import tokenization\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from transformer.model import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'kor_vocab_length': 50000,\n 'eng_vocab_length': 28998,\n 'd_model': 768,\n 'd_ff': 2048,\n 'd_k': 64,\n 'd_v': 64,\n 'num_layers': 12,\n 'num_heads': 8,\n 'start_word': '[SOS]',\n 'end_word': '[EOS]',\n 'sep_word': '[SEP]',\n 'cls_word': '[CLS]',\n 'pad_word': '[PAD]',\n 'mask_word': '[MASK]'}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read configuration file\n",
    "config = json.load(open('config.json'))\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configure device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From /Users/chageumgang/Desktop/transformer_nlp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n\n"
    },
    {
     "data": {
      "text/plain": "['I', 'love', 'you']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configure tokenizer\n",
    "tokenizer = tokenization.FullTokenizer(\n",
    "    vocab_file='vocab/eng_vocab.txt', do_lower_case=False)\n",
    "tokenizer.tokenize('I love you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[['Mr', '.', 'Cass', '##ius', 'crossed', 'the', 'highway', ',', 'and', 'stopped', 'suddenly', '.'], ['Something', 'g', '##lit', '##tered', 'in', 'the', 'nearest', 'red', 'pool', 'before', 'him', '.'], ['Gold', ',', 'surely', '!']]\n[[1830, 121, 17502, 3287, 3811, 1105, 4085, 119, 1107, 2143, 2842, 121], [4264, 178, 12890, 7657, 1109, 1105, 6832, 1896, 4530, 1198, 1142, 121], [3489, 119, 9931, 108]]\n"
    }
   ],
   "source": [
    "# define sample dataset\n",
    "dataset = ['Mr. Cassius crossed the highway, and stopped suddenly.',\n",
    "        'Something glittered in the nearest red pool before him.',\n",
    "        'Gold, surely!']\n",
    "tokenized_text = [tokenizer.tokenize(t) for t in dataset]\n",
    "tokenized_ids = [tokenizer.convert_tokens_to_ids(t) for t in tokenized_text]\n",
    "print(tokenized_text)\n",
    "print(tokenized_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "-----------------\n[103, 1830, 121, 17502, 3287, 3811, 1105, 4085, 119, 105, 2143, 2842, 121, 104, 4264, 178, 12890, 7657, 105, 1105, 6832, 1896, 4530, 1198, 1142, 121, 104, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n[2143, 1107, 1109, 1105, 0]\n[10, 9, 18, 19, 0]\nTrue\n[103, 4264, 178, 105, 7657, 1109, 1105, 105, 1896, 4530, 1198, 1142, 3892, 104, 3489, 119, 9931, 108, 104, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n[6832, 121, 12890, 0, 0]\n[7, 12, 3, 0, 0]\nTrue\n[103, 4264, 178, 12890, 105, 1109, 1105, 6832, 5468, 105, 1198, 1142, 21089, 104, 1830, 121, 17502, 3287, 3811, 1105, 4085, 119, 1107, 2143, 2842, 121, 104, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n[121, 1896, 7657, 4530, 0]\n[12, 8, 4, 9, 0]\nFalse\n[103, 3489, 119, 105, 108, 104, 1830, 121, 105, 3287, 3811, 1105, 4085, 105, 1107, 2143, 2842, 121, 104, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n[9931, 17502, 119, 0, 0]\n[3, 8, 13, 0, 0]\nFalse\n"
    }
   ],
   "source": [
    "## [text[0], text[1]] positive data\n",
    "## [text[1], text[2]] positive data\n",
    "## [text[1], text[0]] negative data\n",
    "## [text[2], text[0]] negative data\n",
    "\n",
    "max_pred = 5\n",
    "token_length = 50\n",
    "\n",
    "pairs = [(0, 1, True), (1, 2, True), (1, 0, False), (2, 0, False)]\n",
    "\n",
    "input_ids, segment_ids, masked_ids, masked_poses, isNexts = [], [], [], [], []\n",
    "\n",
    "cls_idx = tokenizer.convert_tokens_to_ids([config['cls_word']])[0]\n",
    "sep_idx = tokenizer.convert_tokens_to_ids([config['sep_word']])[0]\n",
    "pad_idx = tokenizer.convert_tokens_to_ids([config['pad_word']])[0]\n",
    "mask_idx = tokenizer.convert_tokens_to_ids([config['mask_word']])[0]\n",
    "\n",
    "for pair in pairs:\n",
    "\n",
    "    tokens_a, tokens_b = tokenized_ids[pair[0]], tokenized_ids[pair[1]]\n",
    "    isNext = pair[2]\n",
    "\n",
    "    input_id = [cls_idx] + tokens_a + [sep_idx] + tokens_b + [sep_idx]\n",
    "    segment_id = [0] * (1 + len(tokens_a) + 1) + [1] * (len(tokens_b) + 1)\n",
    "    \n",
    "    n_pred = min(max_pred, max(1, int(round(len(input_id) * 0.15))))\n",
    "    cand_masked_pos = [i for i, token in enumerate(input_id) if token != cls_idx and token != sep_idx]\n",
    "    np.random.shuffle(cand_masked_pos)\n",
    "\n",
    "    masked_id, masked_pos = [], []\n",
    "    for pos in cand_masked_pos[:n_pred]:\n",
    "        masked_pos.append(pos)\n",
    "        masked_id.append(input_id[pos])\n",
    "        if np.random.rand() < 0.8:\n",
    "            input_id[pos] = mask_idx\n",
    "        elif np.random.rand() < 0.5:\n",
    "            input_id[pos] = np.random.choice(config['eng_vocab_length'])\n",
    "\n",
    "    if max_pred > n_pred:\n",
    "        n_pad = max_pred - n_pred\n",
    "        masked_id.extend([0] * n_pad)\n",
    "        masked_pos.extend([0] * n_pad)\n",
    "\n",
    "    n_pad = token_length - len(input_id)\n",
    "    input_id.extend([pad_idx] * n_pad)\n",
    "    segment_id.extend([pad_idx] * n_pad)\n",
    "\n",
    "    input_ids.append(input_id)\n",
    "    segment_ids.append(segment_id)\n",
    "    masked_ids.append(masked_id)\n",
    "    masked_poses.append(masked_pos)\n",
    "    isNexts.append(isNext)\n",
    "\n",
    "print('-----------------')\n",
    "for i in range(len(input_ids)):\n",
    "    print(f'{input_ids[i]}')\n",
    "    print(f'{segment_ids[i]}')\n",
    "    print(f'{masked_ids[i]}')\n",
    "    print(f'{masked_poses[i]}')\n",
    "    print(f'{isNexts[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ids to torch tensor\n",
    "input_ids_tensor = torch.as_tensor(input_ids, dtype=torch.long).to(device)\n",
    "segment_ids_tensor = torch.as_tensor(segment_ids, dtype=torch.long).to(device)\n",
    "masked_ids_tensor = torch.as_tensor(masked_ids, dtype=torch.long).to(device)\n",
    "masked_poses_tensor = torch.as_tensor(masked_poses, dtype=torch.long).to(device)\n",
    "isNexts_tensor = torch.as_tensor(isNexts, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "BertModel(\n  (tok_embed): Embedding(28998, 768)\n  (pos_embed): PositionalEncoding(\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (seg_embed): Embedding(2, 768)\n  (layers): ModuleList(\n    (0): EncoderLayer(\n      (enc_self_attn): MultiHeadAttention(\n        (WQ): Linear(in_features=768, out_features=512, bias=True)\n        (WK): Linear(in_features=768, out_features=512, bias=True)\n        (WV): Linear(in_features=768, out_features=512, bias=True)\n        (linear): Linear(in_features=512, out_features=768, bias=True)\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n      (pos_ffn): PoswiseFeedForwardNet(\n        (l1): Linear(in_features=768, out_features=2048, bias=True)\n        (l2): Linear(in_features=2048, out_features=768, bias=True)\n        (relu): GELU()\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (1): EncoderLayer(\n      (enc_self_attn): MultiHeadAttention(\n        (WQ): Linear(in_features=768, out_features=512, bias=True)\n        (WK): Linear(in_features=768, out_features=512, bias=True)\n        (WV): Linear(in_features=768, out_features=512, bias=True)\n        (linear): Linear(in_features=512, out_features=768, bias=True)\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n      (pos_ffn): PoswiseFeedForwardNet(\n        (l1): Linear(in_features=768, out_features=2048, bias=True)\n        (l2): Linear(in_features=2048, out_features=768, bias=True)\n        (relu): GELU()\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (2): EncoderLayer(\n      (enc_self_attn): MultiHeadAttention(\n        (WQ): Linear(in_features=768, out_features=512, bias=True)\n        (WK): Linear(in_features=768, out_features=512, bias=True)\n        (WV): Linear(in_features=768, out_features=512, bias=True)\n        (linear): Linear(in_features=512, out_features=768, bias=True)\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n      (pos_ffn): PoswiseFeedForwardNet(\n        (l1): Linear(in_features=768, out_features=2048, bias=True)\n        (l2): Linear(in_features=2048, out_features=768, bias=True)\n        (relu): GELU()\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (3): EncoderLayer(\n      (enc_self_attn): MultiHeadAttention(\n        (WQ): Linear(in_features=768, out_features=512, bias=True)\n        (WK): Linear(in_features=768, out_features=512, bias=True)\n        (WV): Linear(in_features=768, out_features=512, bias=True)\n        (linear): Linear(in_features=512, out_features=768, bias=True)\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n      (pos_ffn): PoswiseFeedForwardNet(\n        (l1): Linear(in_features=768, out_features=2048, bias=True)\n        (l2): Linear(in_features=2048, out_features=768, bias=True)\n        (relu): GELU()\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (4): EncoderLayer(\n      (enc_self_attn): MultiHeadAttention(\n        (WQ): Linear(in_features=768, out_features=512, bias=True)\n        (WK): Linear(in_features=768, out_features=512, bias=True)\n        (WV): Linear(in_features=768, out_features=512, bias=True)\n        (linear): Linear(in_features=512, out_features=768, bias=True)\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n      (pos_ffn): PoswiseFeedForwardNet(\n        (l1): Linear(in_features=768, out_features=2048, bias=True)\n        (l2): Linear(in_features=2048, out_features=768, bias=True)\n        (relu): GELU()\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (5): EncoderLayer(\n      (enc_self_attn): MultiHeadAttention(\n        (WQ): Linear(in_features=768, out_features=512, bias=True)\n        (WK): Linear(in_features=768, out_features=512, bias=True)\n        (WV): Linear(in_features=768, out_features=512, bias=True)\n        (linear): Linear(in_features=512, out_features=768, bias=True)\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n      (pos_ffn): PoswiseFeedForwardNet(\n        (l1): Linear(in_features=768, out_features=2048, bias=True)\n        (l2): Linear(in_features=2048, out_features=768, bias=True)\n        (relu): GELU()\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (6): EncoderLayer(\n      (enc_self_attn): MultiHeadAttention(\n        (WQ): Linear(in_features=768, out_features=512, bias=True)\n        (WK): Linear(in_features=768, out_features=512, bias=True)\n        (WV): Linear(in_features=768, out_features=512, bias=True)\n        (linear): Linear(in_features=512, out_features=768, bias=True)\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n      (pos_ffn): PoswiseFeedForwardNet(\n        (l1): Linear(in_features=768, out_features=2048, bias=True)\n        (l2): Linear(in_features=2048, out_features=768, bias=True)\n        (relu): GELU()\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (7): EncoderLayer(\n      (enc_self_attn): MultiHeadAttention(\n        (WQ): Linear(in_features=768, out_features=512, bias=True)\n        (WK): Linear(in_features=768, out_features=512, bias=True)\n        (WV): Linear(in_features=768, out_features=512, bias=True)\n        (linear): Linear(in_features=512, out_features=768, bias=True)\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n      (pos_ffn): PoswiseFeedForwardNet(\n        (l1): Linear(in_features=768, out_features=2048, bias=True)\n        (l2): Linear(in_features=2048, out_features=768, bias=True)\n        (relu): GELU()\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (8): EncoderLayer(\n      (enc_self_attn): MultiHeadAttention(\n        (WQ): Linear(in_features=768, out_features=512, bias=True)\n        (WK): Linear(in_features=768, out_features=512, bias=True)\n        (WV): Linear(in_features=768, out_features=512, bias=True)\n        (linear): Linear(in_features=512, out_features=768, bias=True)\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n      (pos_ffn): PoswiseFeedForwardNet(\n        (l1): Linear(in_features=768, out_features=2048, bias=True)\n        (l2): Linear(in_features=2048, out_features=768, bias=True)\n        (relu): GELU()\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (9): EncoderLayer(\n      (enc_self_attn): MultiHeadAttention(\n        (WQ): Linear(in_features=768, out_features=512, bias=True)\n        (WK): Linear(in_features=768, out_features=512, bias=True)\n        (WV): Linear(in_features=768, out_features=512, bias=True)\n        (linear): Linear(in_features=512, out_features=768, bias=True)\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n      (pos_ffn): PoswiseFeedForwardNet(\n        (l1): Linear(in_features=768, out_features=2048, bias=True)\n        (l2): Linear(in_features=2048, out_features=768, bias=True)\n        (relu): GELU()\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (10): EncoderLayer(\n      (enc_self_attn): MultiHeadAttention(\n        (WQ): Linear(in_features=768, out_features=512, bias=True)\n        (WK): Linear(in_features=768, out_features=512, bias=True)\n        (WV): Linear(in_features=768, out_features=512, bias=True)\n        (linear): Linear(in_features=512, out_features=768, bias=True)\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n      (pos_ffn): PoswiseFeedForwardNet(\n        (l1): Linear(in_features=768, out_features=2048, bias=True)\n        (l2): Linear(in_features=2048, out_features=768, bias=True)\n        (relu): GELU()\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (11): EncoderLayer(\n      (enc_self_attn): MultiHeadAttention(\n        (WQ): Linear(in_features=768, out_features=512, bias=True)\n        (WK): Linear(in_features=768, out_features=512, bias=True)\n        (WV): Linear(in_features=768, out_features=512, bias=True)\n        (linear): Linear(in_features=512, out_features=768, bias=True)\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n      (pos_ffn): PoswiseFeedForwardNet(\n        (l1): Linear(in_features=768, out_features=2048, bias=True)\n        (l2): Linear(in_features=2048, out_features=768, bias=True)\n        (relu): GELU()\n        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n  (fc): Linear(in_features=768, out_features=768, bias=True)\n  (active1): Tanh()\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (linear): Linear(in_features=768, out_features=768, bias=True)\n  (active2): GELU()\n  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  (decoder): Linear(in_features=768, out_features=28998, bias=False)\n)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## configure model, optimizer, criterion\n",
    "\n",
    "pad_index = tokenizer.convert_tokens_to_ids([config['pad_word']])[0]\n",
    "\n",
    "bert = BertModel(\n",
    "    vocab_size=config['eng_vocab_length'],\n",
    "    d_model=config['d_model'],\n",
    "    d_ff=config['d_ff'], d_k=config['d_k'],\n",
    "    d_v=config['d_v'], n_heads=config['num_heads'],\n",
    "    n_layers=config['num_layers'], pad_index=pad_index,\n",
    "    device=device).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(bert.parameters(), lr=5e-5, betas=(0.9, 0.999), weight_decay=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0 110.25227355957031\n1 47.35847854614258\n2 34.622554779052734\n3 22.38869285583496\n4 13.62109375\n5 7.63401985168457\n6 3.9623594284057617\n7 2.758429527282715\n8 3.287774085998535\n9 3.4298293590545654\n10 2.2902426719665527\n11 2.5123467445373535\n12 2.145576000213623\n13 1.2739777565002441\n14 0.8557220697402954\n15 1.2299394607543945\n16 1.0996782779693604\n17 1.6305320262908936\n18 0.510784387588501\n19 0.833055853843689\n20 0.6597347259521484\n21 0.6508806347846985\n22 0.47196927666664124\n23 0.45319467782974243\n24 0.6112233996391296\n25 0.42565232515335083\n26 0.42086994647979736\n27 0.46858450770378113\n28 0.3950214385986328\n29 0.3883059322834015\n30 0.3893374502658844\n31 0.3799106180667877\n32 0.3650440275669098\n33 0.3586336672306061\n34 0.3481409549713135\n35 0.33903467655181885\n36 0.33206090331077576\n37 0.32673773169517517\n38 0.32280218601226807\n39 0.3178752362728119\n40 0.3109605610370636\n41 0.3043636083602905\n42 0.29847440123558044\n43 0.2930338382720947\n44 0.2878718376159668\n45 0.28281617164611816\n46 0.27770036458969116\n47 0.27243778109550476\n48 0.2670462131500244\n49 0.2615998387336731\n"
    }
   ],
   "source": [
    "## training.......\n",
    "bert_step = 0\n",
    "for epoch in range(50):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    logits_lm, logits_clsf, _ = bert(input_ids_tensor, segment_ids_tensor, masked_poses_tensor)\n",
    "    loss_lm = criterion(logits_lm.transpose(1, 2), masked_ids_tensor)\n",
    "    loss_clsf = criterion(logits_clsf, isNexts_tensor)\n",
    "    loss = loss_lm + loss_clsf\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(epoch, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "--------\n--------\npredict\ntensor([[ 2143,  1107,  1109,  1105,     0],\n        [ 6832,   121, 12890,     0,     0],\n        [  121,  1896,  7657,  4530,     0],\n        [ 9931, 17502,   119,     0,     0]])\nanswer\ntensor([[ 2143,  1107,  1109,  1105,     0],\n        [ 6832,   121, 12890,     0,     0],\n        [  121,  1896,  7657,  4530,     0],\n        [ 9931, 17502,   119,     0,     0]])\n--------\npredict\ntensor([1, 1, 0, 0])\nanswer\ntensor([1, 1, 0, 0])\n--------\n--------\n"
    }
   ],
   "source": [
    "## check correctly trained\n",
    "\n",
    "logits_lm, logits_clsf, _ = bert(input_ids_tensor, segment_ids_tensor, masked_poses_tensor)\n",
    "\n",
    "print('--------')\n",
    "print('--------')\n",
    "print('predict')\n",
    "print(torch.argmax(logits_lm, axis=2))\n",
    "print('answer')\n",
    "print(masked_ids_tensor)\n",
    "print('--------')\n",
    "\n",
    "print('predict')\n",
    "print(torch.argmax(logits_clsf, axis=1))\n",
    "print('answer')\n",
    "print(isNexts_tensor)\n",
    "print('--------')\n",
    "print('--------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}